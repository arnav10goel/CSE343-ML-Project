{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "yzkRRYqUM6RW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/arnav/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Download the stopwords\n",
        "stopwords = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2v6rBbSxNOun"
      },
      "outputs": [],
      "source": [
        "# Loading datasets\n",
        "train_df = pd.read_csv('/Users/arnav/Desktop/MachineLearning/ML_CSE343 Project/CSE343-ML-Project/Data/Preprocessed-Data/train.csv')\n",
        "test_df = pd.read_csv('/Users/arnav/Desktop/MachineLearning/ML_CSE343 Project/CSE343-ML-Project/Data/Preprocessed-Data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text    object\n",
            "dtype: object\n",
            "text    object\n",
            "dtype: object\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>omg guys hello father may please acquire nouri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>suicidal people sub if need talk messege im</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>existential question the opposite ptsd memory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>can imagine getting old me neitherwrinkles wei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>imagine rich lmao sounds kinda like control wo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  omg guys hello father may please acquire nouri...\n",
              "1        suicidal people sub if need talk messege im\n",
              "2      existential question the opposite ptsd memory\n",
              "3  can imagine getting old me neitherwrinkles wei...\n",
              "4  imagine rich lmao sounds kinda like control wo..."
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print datatypes\n",
        "print(train_df.dtypes)\n",
        "print(test_df.dtypes)\n",
        "\n",
        "# Convert to string\n",
        "train_df['text'] = train_df['text'].astype(str)\n",
        "test_df['text'] = test_df['text'].astype(str)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>seeing everyone else better real trigger mebas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>why cant i ever normalim always pain i dont th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i wasted lifei basically wasted life i never b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the voice tells kill selfthe voice abuser cons...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i figured today complete survey get gems downl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  seeing everyone else better real trigger mebas...\n",
              "1  why cant i ever normalim always pain i dont th...\n",
              "2  i wasted lifei basically wasted life i never b...\n",
              "3  the voice tells kill selfthe voice abuser cons...\n",
              "4  i figured today complete survey get gems downl..."
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing the data\n",
        "# Removing the stopwords\n",
        "train_df['text'] = train_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "test_df['text'] = test_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "train_df['text'] = train_df['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
        "test_df['text'] = test_df['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "train_df['text'] = train_df['text'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
        "test_df['text'] = test_df['text'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = TweetTokenizer()\n",
        "train_df['text'] = train_df['text'].apply(lambda x: tokenizer.tokenize(x))\n",
        "test_df['text'] = test_df['text'].apply(lambda x: tokenizer.tokenize(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the list of tokens into a string\n",
        "train_df['text'] = train_df['text'].apply(lambda x: ' '.join(x))\n",
        "test_df['text'] = test_df['text'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "train_vectors = vectorizer.fit_transform(train_df['text'])\n",
        "test_vectors = vectorizer.transform(test_df['text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(22500, 10000)\n",
            "(7500, 10000)\n"
          ]
        }
      ],
      "source": [
        "# Check the shape of the vectors\n",
        "print(train_vectors.shape)\n",
        "print(test_vectors.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the training data to an array\n",
        "train_tfidf = train_vectors.toarray()\n",
        "\n",
        "# Convert the test data to an array\n",
        "test_tfidf = test_vectors.toarray()\n",
        "\n",
        "# Save the numpy arrays as npy files\n",
        "np.save('train_tfidf.npy', train_tfidf)\n",
        "np.save('test_tfidf.npy', test_tfidf)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
