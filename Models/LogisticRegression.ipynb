{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 1000)\n",
      "(7500, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Open the .csv files\n",
    "X_train = pd.read_csv('/Users/arnav/Desktop/MachineLearning/ML_CSE343 Project/train_tfidf.csv')\n",
    "X_test = pd.read_csv('/Users/arnav/Desktop/MachineLearning/ML_CSE343 Project/test_tfidf.csv')\n",
    "\n",
    "X_train = X_train.drop(['Unnamed: 0'], axis=1)\n",
    "X_test = X_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# Check the shape of the data\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features into a numpy array\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 1)\n",
      "(7500, 1)\n"
     ]
    }
   ],
   "source": [
    "# Open the labels\n",
    "y_train_df = pd.read_csv('/Users/arnav/Desktop/MachineLearning/ML_CSE343 Project/CSE343-ML-Project/Data/Preprocessed-Data/train_labels.csv')\n",
    "y_test_df = pd.read_csv('/Users/arnav/Desktop/MachineLearning/ML_CSE343 Project/CSE343-ML-Project/Data/Preprocessed-Data/test_labels.csv')\n",
    "\n",
    "# Check the shape of the labels\n",
    "print(y_train_df.shape)\n",
    "print(y_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500,)\n",
      "(7500,)\n"
     ]
    }
   ],
   "source": [
    "# Convert class to non_suicide = 0 and suicide = 1\n",
    "y_train_temp = y_train_df['class'].values\n",
    "y_test_temp = y_test_df['class'].values\n",
    "\n",
    "# Check the shape of the labels\n",
    "print(y_train_temp.shape)\n",
    "print(y_test_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500,)\n",
      "(7500,)\n"
     ]
    }
   ],
   "source": [
    "# Making the Labels Numeric\n",
    "y_train = np.array([0 if label == \"non-suicide\" else 1 for label in y_train_temp])\n",
    "y_test = np.array([0 if label == \"non-suicide\" else 1 for label in y_test_temp])\n",
    "\n",
    "# Check the shape of the labels\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004686103127390068 0.0312074847455884\n"
     ]
    }
   ],
   "source": [
    "# Standard Preprocessing\n",
    "# Check the mean and standard deviation of the data\n",
    "print(np.mean(X_train), np.std(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_base = LogisticRegression()\n",
    "\n",
    "# Fit\n",
    "lr_base.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr_base.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Logistic Regression: Test Data\n",
      "Accuracy: 0.9150666666666667\n",
      "Confusion Matrix:\n",
      "[[3429  279]\n",
      " [ 358 3434]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      3708\n",
      "           1       0.92      0.91      0.92      3792\n",
      "\n",
      "    accuracy                           0.92      7500\n",
      "   macro avg       0.92      0.92      0.92      7500\n",
      "weighted avg       0.92      0.92      0.92      7500\n",
      "\n",
      "AUC Score: 0.9151739994264881\n",
      "Weighted F1-score: 0.9150672630876725\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy\n",
    "print(\"Base Logistic Regression: Test Data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Logistic Regression: Training Data\n",
      "Accuracy: 0.9210666666666667\n",
      "Confusion Matrix:\n",
      "[[10549   743]\n",
      " [ 1033 10175]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     11292\n",
      "           1       0.93      0.91      0.92     11208\n",
      "\n",
      "    accuracy                           0.92     22500\n",
      "   macro avg       0.92      0.92      0.92     22500\n",
      "weighted avg       0.92      0.92      0.92     22500\n",
      "\n",
      "AUC Score: 0.9210174473068803\n",
      "Weighted F1-score: 0.9210497511596902\n"
     ]
    }
   ],
   "source": [
    "# Predict on training data\n",
    "y_pred_train = lr_base.predict(X_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Base Logistic Regression: Training Data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_train, y_pred_train))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_train, y_pred_train, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.7s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.7s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   1.2s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   7.3s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   8.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   8.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   4.8s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=  13.1s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   4.5s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=  13.7s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=  13.6s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=  13.1s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=  13.7s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   6.0s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   6.4s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   6.1s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   6.7s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   6.7s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   9.7s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   9.4s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  10.2s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   3.2s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   2.3s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=  13.2s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=  13.8s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  15.5s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=  14.8s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   2.5s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=  17.6s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.3s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=  14.5s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=  14.8s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   9.2s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   9.9s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  10.6s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   9.8s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=  10.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=  12.5s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=  12.5s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=  12.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.4s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   8.4s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   8.4s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  26.1s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.7s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  29.6s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  32.6s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  28.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   6.4s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   5.9s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   6.6s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   7.0s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=  31.8s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   7.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=  16.2s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=  17.4s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=  18.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=  11.4s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=  11.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   5.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.2s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  10.1s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  11.6s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  11.7s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  10.9s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  10.3s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 1.3min\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 1.4min\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 2.1min\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  10.9s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  12.9s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  12.9s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  13.6s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  10.9s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 3.1min\n",
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   9.3s\n",
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=  11.1s\n",
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   8.0s\n",
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   9.6s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   7.8s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 2.8min\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time=  57.7s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 4.7min\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.2min\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time=  45.1s\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time=  36.0s\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time=  49.1s\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 4.4min\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 5.5min\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 6.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.796      0.79448889 0.8708     0.8708\n",
      " 0.87302222 0.8708            nan        nan 0.88066667 0.88035556\n",
      " 0.89826667 0.89826667 0.8984     0.89826667        nan        nan\n",
      " 0.90924444 0.90924444 0.91008889 0.91008889 0.91008889 0.91008889\n",
      "        nan        nan 0.90742222 0.90742222 0.90866667 0.90866667\n",
      " 0.90866667 0.90866667        nan        nan 0.90537778 0.90533333\n",
      " 0.90555556 0.9056     0.90555556 0.90555556]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 7.2min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Grid Search to find the best parameters for Logistic Regression\n",
    "\n",
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "lr_best = LogisticRegression(max_iter=1000, C=best_parameters['C'], penalty=best_parameters['penalty'], solver=best_parameters['solver'])\n",
    "\n",
    "# Fit the best model    \n",
    "lr_best.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred_test_best = lr_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression: Test Data\n",
      "Accuracy: 0.9150666666666667\n",
      "Confusion Matrix:\n",
      "[[3429  279]\n",
      " [ 358 3434]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      3708\n",
      "           1       0.92      0.91      0.92      3792\n",
      "\n",
      "    accuracy                           0.92      7500\n",
      "   macro avg       0.92      0.92      0.92      7500\n",
      "weighted avg       0.92      0.92      0.92      7500\n",
      "\n",
      "AUC Score: 0.9151739994264881\n",
      "Weighted F1-score: 0.9150672630876725\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy\n",
    "print(\"Best Logistic Regression: Test Data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.plot(recall, precision, 'b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression: Training Data\n",
      "Accuracy: 0.9211111111111111\n",
      "Confusion Matrix:\n",
      "[[10549   743]\n",
      " [ 1032 10176]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     11292\n",
      "           1       0.93      0.91      0.92     11208\n",
      "\n",
      "    accuracy                           0.92     22500\n",
      "   macro avg       0.92      0.92      0.92     22500\n",
      "weighted avg       0.92      0.92      0.92     22500\n",
      "\n",
      "AUC Score: 0.9210620582990289\n",
      "Weighted F1-score: 0.921094308497212\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "# Predict the labels of the training set\n",
    "y_pred_train_best = lr_best.predict(X_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Best Logistic Regression: Training Data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train_best))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_pred_train_best))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_train_best))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_train, y_pred_train_best))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_train, y_pred_train_best, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot No. of Components vs. Explained Variance and mark at 75% explained variance\n",
    "pca = PCA().fit(X_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('No. of Components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.axhline(y=0.75, color='r', linestyle='-')\n",
    "plt.text(0.5, 0.8, '75%', color = 'red', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Components: 434\n"
     ]
    }
   ],
   "source": [
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components = np.argmax(cumulative_explained_variance >= 0.75) + 1\n",
    "print(\"No. of Components:\", n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on the data and extract the features that explain 85% of the variance\n",
    "pca = PCA(n_components=0.75)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 434)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Logistic Regression \n",
    "# Initialize Logistic Regression\n",
    "lr_pca = LogisticRegression(max_iter=1000, C=best_parameters['C'], penalty=best_parameters['penalty'], solver=best_parameters['solver'])\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_test_pca = lr_pca.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with PCA: Test Data\n",
      "Accuracy Score: 0.9134666666666666\n",
      "Confusion Matrix:\n",
      " [[3431  277]\n",
      " [ 372 3420]]\n",
      "AUC Score: 0.9135976950281977\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91      3708\n",
      "           1       0.93      0.90      0.91      3792\n",
      "\n",
      "    accuracy                           0.91      7500\n",
      "   macro avg       0.91      0.91      0.91      7500\n",
      "weighted avg       0.91      0.91      0.91      7500\n",
      "\n",
      "Weighted F1-score: 0.9134650590661715\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score\n",
    "print(\"Logistic Regression with PCA: Test Data\")\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with PCA: Training Data\n",
      "Accuracy Score: 0.9144\n",
      "Confusion Matrix:\n",
      " [[10468   824]\n",
      " [ 1102 10106]]\n",
      "AUC Score: 0.9143526788592632\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     11292\n",
      "           1       0.92      0.90      0.91     11208\n",
      "\n",
      "    accuracy                           0.91     22500\n",
      "   macro avg       0.91      0.91      0.91     22500\n",
      "weighted avg       0.91      0.91      0.91     22500\n",
      "\n",
      "Weighted F1-score: 0.9143829794132429\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "# Predict on the training data\n",
    "y_pred_train_pca = lr_pca.predict(X_train_pca)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Logistic Regression with PCA: Training Data\")\n",
    "print(\"Accuracy Score:\", accuracy_score(y_train, y_pred_train_pca))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_pred_train_pca))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_train, y_pred_train_pca))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_pred_train_pca))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_train, y_pred_train_pca, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
