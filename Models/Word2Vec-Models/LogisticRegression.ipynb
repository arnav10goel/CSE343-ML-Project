{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 512)\n",
      "(7500, 512)\n"
     ]
    }
   ],
   "source": [
    "# Open the .csv files\n",
    "X_train = pd.read_csv('/Users/arnav/Desktop/MachineLearning/ML_CSE343 Project/CSE343-ML-Project/Embeddings/train_word2vec.csv')\n",
    "X_test = pd.read_csv('/Users/arnav/Desktop/MachineLearning/ML_CSE343 Project/CSE343-ML-Project/Embeddings/test_word2vec.csv')\n",
    "\n",
    "X_train = X_train.drop(['Unnamed: 0'], axis=1)\n",
    "X_test = X_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# Check the shape of the data\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features into a numpy array\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 1)\n",
      "(7500, 1)\n"
     ]
    }
   ],
   "source": [
    "# Open the labels\n",
    "y_train_df = pd.read_csv('/Users/arnav/Desktop/MachineLearning/ML_CSE343 Project/CSE343-ML-Project/Data/Preprocessed-Data/train_labels.csv')\n",
    "y_test_df = pd.read_csv('/Users/arnav/Desktop/MachineLearning/ML_CSE343 Project/CSE343-ML-Project/Data/Preprocessed-Data/test_labels.csv')\n",
    "\n",
    "# Check the shape of the labels\n",
    "print(y_train_df.shape)\n",
    "print(y_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500,)\n",
      "(7500,)\n"
     ]
    }
   ],
   "source": [
    "# Convert class to non_suicide = 0 and suicide = 1\n",
    "y_train_temp = y_train_df['class'].values\n",
    "y_test_temp = y_test_df['class'].values\n",
    "\n",
    "# Check the shape of the labels\n",
    "print(y_train_temp.shape)\n",
    "print(y_test_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500,)\n",
      "(7500,)\n"
     ]
    }
   ],
   "source": [
    "# Making the Labels Numeric\n",
    "y_train = np.array([0 if label == \"non-suicide\" else 1 for label in y_train_temp])\n",
    "y_test = np.array([0 if label == \"non-suicide\" else 1 for label in y_test_temp])\n",
    "\n",
    "# Check the shape of the labels\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0029877624999040935 0.18965241040518302\n"
     ]
    }
   ],
   "source": [
    "# Standard Preprocessing\n",
    "# Check the mean and standard deviation of the data\n",
    "print(np.mean(X_train), np.std(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr_base = LogisticRegression()\n",
    "\n",
    "# Fit\n",
    "lr_base.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr_base.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Logistic Regression: Test Data\n",
      "Accuracy: 0.8982666666666667\n",
      "Confusion Matrix:\n",
      "[[3245  463]\n",
      " [ 300 3492]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.89      3708\n",
      "           1       0.88      0.92      0.90      3792\n",
      "\n",
      "    accuracy                           0.90      7500\n",
      "   macro avg       0.90      0.90      0.90      7500\n",
      "weighted avg       0.90      0.90      0.90      7500\n",
      "\n",
      "AUC Score: 0.8980104597654063\n",
      "Weighted F1-score: 0.8981937718582631\n",
      "Macro F1 Score: 0.8981562064355275\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy\n",
    "print(\"Base Logistic Regression: Test Data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# Calculate macro F1 Score\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print Macro F1 Score\n",
    "print(f'Macro F1 Score: {macro_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Logistic Regression: Training Data\n",
      "Accuracy: 0.8900888888888889\n",
      "Confusion Matrix:\n",
      "[[ 9876  1416]\n",
      " [ 1057 10151]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89     11292\n",
      "           1       0.88      0.91      0.89     11208\n",
      "\n",
      "    accuracy                           0.89     22500\n",
      "   macro avg       0.89      0.89      0.89     22500\n",
      "weighted avg       0.89      0.89      0.89     22500\n",
      "\n",
      "AUC Score: 0.8901469251885513\n",
      "Weighted F1-score: 0.8900674516629439\n"
     ]
    }
   ],
   "source": [
    "# Predict on training data\n",
    "y_pred_train = lr_base.predict(X_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Base Logistic Regression: Training Data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_train, y_pred_train))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_train, y_pred_train, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.3s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.3s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.3s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.3s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.4s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   4.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   4.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   4.3s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   4.4s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   4.5s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   3.6s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   3.5s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   3.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   2.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   3.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   5.6s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   6.7s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   7.3s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   3.9s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   3.3s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   4.4s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   4.2s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   3.9s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   3.9s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   4.2s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   2.7s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=  29.5s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   3.9s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   3.6s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   3.3s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   4.4s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=  31.9s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=  32.1s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=  37.2s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=  37.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   3.5s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   4.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   4.5s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   3.9s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   3.7s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   5.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   8.6s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   8.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   7.1s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   9.4s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   9.3s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   9.1s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   9.2s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   9.7s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   8.1s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   8.8s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   7.9s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   8.9s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   7.4s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 1.6min\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 1.9min\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.0min\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   4.1s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   4.5s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.2min\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   5.4s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   5.6s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   6.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   6.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   6.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.9s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   6.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   5.9s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   7.7s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   7.4s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   6.5s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   6.1s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   6.2s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  40.3s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  38.1s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  40.3s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  42.6s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  42.6s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 4.3min\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 4.3min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 1.5min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 4.3min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 1.6min\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 4.5min\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   9.3s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   9.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=  10.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=  10.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  12.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  15.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  14.1s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.0min\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  14.4s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  15.4s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  18.5s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  20.1s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  15.9s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  18.5s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 5.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 2.5min\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 5.0min\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 5.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 5.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 5.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 5.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 5.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 5.3min\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  33.6s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  32.5s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  34.1s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  36.3s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  33.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=  25.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 6.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=  28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=  29.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=  30.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=  29.9s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  51.9s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  56.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=14.6min\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=14.5min\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=14.8min\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  56.7s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  55.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  46.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 6.5min\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=15.1min\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=15.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "50 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.87355556 0.87008889 0.88013333 0.88013333\n",
      " 0.88008889 0.88017778        nan        nan 0.88257778 0.88213333\n",
      " 0.88426667 0.88431111 0.8844     0.88426667        nan        nan\n",
      " 0.88715556 0.88706667 0.88817778 0.88817778 0.88786667 0.88817778\n",
      "        nan        nan 0.89302222 0.8908     0.89022222 0.89017778\n",
      " 0.89017778 0.88991111        nan        nan 0.89626667 0.89168889\n",
      " 0.89408889 0.89422222 0.89408889 0.89164444]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 2.1min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Grid Search to find the best parameters for Logistic Regression\n",
    "\n",
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "lr_best = LogisticRegression(max_iter=1000, C=best_parameters['C'], penalty=best_parameters['penalty'], solver=best_parameters['solver'])\n",
    "\n",
    "# Fit the best model    \n",
    "lr_best.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred_test_best = lr_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression: Test Data\n",
      "Accuracy: 0.8982666666666667\n",
      "Confusion Matrix:\n",
      "[[3245  463]\n",
      " [ 300 3492]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.89      3708\n",
      "           1       0.88      0.92      0.90      3792\n",
      "\n",
      "    accuracy                           0.90      7500\n",
      "   macro avg       0.90      0.90      0.90      7500\n",
      "weighted avg       0.90      0.90      0.90      7500\n",
      "\n",
      "AUC Score: 0.8980104597654063\n",
      "Weighted F1-score: 0.8981937718582631\n",
      "Macro F1-score: 0.8981562064355275\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy\n",
    "print(\"Best Logistic Regression: Test Data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# Print macro F1-score\n",
    "print(\"Macro F1-score:\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression: Training Data\n",
      "Accuracy: 0.9008888888888889\n",
      "Confusion Matrix:\n",
      "[[10016  1276]\n",
      " [  954 10254]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     11292\n",
      "           1       0.89      0.91      0.90     11208\n",
      "\n",
      "    accuracy                           0.90     22500\n",
      "   macro avg       0.90      0.90      0.90     22500\n",
      "weighted avg       0.90      0.90      0.90     22500\n",
      "\n",
      "AUC Score: 0.9009409363738212\n",
      "Weighted F1-score: 0.9008738837944499\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "# Predict the labels of the training set\n",
    "y_pred_train_best = lr_best.predict(X_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Best Logistic Regression: Training Data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train_best))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_pred_train_best))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_train_best))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_train, y_pred_train_best))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_train, y_pred_train_best, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkK0lEQVR4nO3deZgdZZn38e8v3UkakpCQhS1JE5YAhh2b1YUIogFnwjuiEuRVNo06sqgwDryOoFFHwYXZEIgMAoOCoOIEjKCyjTooSVgSQgjEsGSBJGSlE3q/3z+qOjnp9HKSdPXpPvX7XNe5upanqu7qdOo+z/NUPaWIwMzM8qtfqQMwM7PSciIwM8s5JwIzs5xzIjAzyzknAjOznKssdQDba+TIkTFu3LhSh2Fm1qfMmTPnzYgY1d66PpcIxo0bx+zZs0sdhplZnyLp1Y7WuWnIzCznnAjMzHLOicDMLOecCMzMcs6JwMws5zJLBJJulbRS0nMdrJekf5O0SNJcScdkFYuZmXUsyxrBbcCkTtafDoxPP1OBGzOMxczMOpDZcwQR8T+SxnVS5EzgjkjGwf6zpGGS9o6I17OKqRxEBJsamtlY30RdYwt1Tc3UNTZT19hCfVMz9Y0tNLUELRE0pz+bmoPmCFpaCn62BM2R7G/LvtOftLes/TJtRzFv3d/2bmfgX0kb/iPZxqnv2JMjxw7r9v2W8oGy0cCSgvml6bJtEoGkqSS1Bqqrq3skuFJasaGO55dv4NXVG3ll9SZeW7OJlW/Vsaa2gdUbG6hvail1iGY9Qip1BL3LHrtVlV0iKFpETAemA9TU1JTd14Ta+iYeXrCCx19cxexX1vLamk2b1w0aUEH1iEHsudtADtpzCCMGDWD4oIEMqaqkqn8FVf37UVVZsXl6YGUFFf2UfqCfkunWn1tNSyhtHGz9/6b0f17h/7/W/4xKl7b9z9nR+o72uXm9/5eb9QqlTATLgLEF82PSZbnQ3BL8fsEKfj5nKY+/uIqGphaGDxrAseN255Mn7suRY4cxbsQgRg4e4AummWWqlIlgBnCxpLuB44H1eegfaGxu4WezlvCjPyzm1dWb2HO3gZx7fDUfOnxvjqnenX79fNE3s56VWSKQdBcwERgpaSlwDdAfICJuAmYCZwCLgE3ABVnF0lv8adGbXDNjPotW1nJ09TC+/MFD+OChe1JZ4cc5zKx0srxr6Jwu1gfw+ayO35vUNTZz7YMv8OM/vcK4EbtyyydrOPUde7jJx8x6hT7RWdyXvfDGBi6962leXFHL+SeN48rTD6Gqf0WpwzIz28yJIEMPL1jBJXc9zaCBldx2wbFMPHiPUodkZrYNJ4KM3DN7CVf+Yi6H7jOUW86rYc/dqkodkplZu5wIMvCbea9z5S/m8q4DR3LzJ97JrgP8azaz3su3q3SzP7y0isvufoajq3d3EjCzPsGJoBu9/OZG/v7Op9h/1CBuPe9YJwEz6xOcCLrJ2w3NfO7OOVRWiP88/1iG7tq/1CGZmRXFX1m7QUTwlV/NY+GKt7jtguMYPWyXUodkZlY01wi6wYxnl/PLp5Zx6SnjOfmgUaUOx8xsuzgR7KQ1Gxv4+v3Pc9TYYVx66vhSh2Nmtt2cCHbStPvn81ZdI9eedQQVHjDOzPogJ4KdMOfVNfzqmeV89uQDOHivIaUOx8xshzgR7KCI4NrfLGTk4IF8buIBpQ7HzGyHORHsoEdeWMmTr6zhsveP9/MCZtanORHsgOaW4LoHFzJuxK5MOXZs1xuYmfViTgQ74P5nl7NwxVtc8cGD6e+XyphZH+er2HaKCG56/K8ctOdgzjhs71KHY2a205wIttPjL67ihTfeYup7D/D7hc2sLDgRbKebH1/MXrtVMfnIfUodiplZt8g0EUiaJGmhpEWSrmxn/b6SHpY0V9JjksZkGc/Omr98PU8sXs0F7xrHgErnUDMrD5ldzSRVADcApwMTgHMkTWhT7HvAHRFxBDAN+HZW8XSHu558jYGV/ZhybHWpQzEz6zZZfq09DlgUEYsjogG4GzizTZkJwCPp9KPtrO81NjU08d9PL+eMw/f2ENNmVlayTASjgSUF80vTZYWeBT6cTv8dMETSiLY7kjRV0mxJs1etWpVJsF359dzXeau+yc8NmFnZKXVD9xXAyZKeBk4GlgHNbQtFxPSIqImImlGjSjPM892zlrD/qEEct9/wkhzfzCwrWY6NsAwo/Po8Jl22WUQsJ60RSBoMnBUR6zKMaYcsWbOJOa+u5R8nHYLkW0bNrLxkWSOYBYyXtJ+kAcAUYEZhAUkjJbXGcBVwa4bx7LCH5r8BwIcO9wNkZlZ+MksEEdEEXAw8BCwA7omI+ZKmSZqcFpsILJT0IrAn8K2s4tkZv3nuDSbsvRvVI3YtdShmZt0u02EzI2ImMLPNsqsLpn8O/DzLGHbWig11zHl1LZefdlCpQzEzy0SpO4t7vdZmodMP36vEkZiZZcOJoAsPPvcGB4waxIF7+A1kZlaenAg6UVvfxKxX1vD+d+xZ6lDMzDLjRNCJPy16k8bm4OSDS/PsgplZT3Ai6MRjC1cxeGAlNfv6ITIzK19OBB2ICB5fuJJ3HTjCI42aWVnzFa4DL62sZfn6OiYevEepQzEzy5QTQQceX5gMbjfR/QNmVuacCDrwxOLV7D9qEHsP3aXUoZiZZcqJoB0tLcHsV9ZwvEcaNbMccCJox8IVb7Ghrsl3C5lZLuQzEUycCFL7n0mTmPXKGsasX8FZNWPbL7Nu3ZZ9bdoEF10Ew4fDAQfAz3627fGuuw6OPBKamnrqDM3MipbpoHO91g9/CBs2bL3siSfgS1+CyZN58uU1jBo8MFl+1VUwefLWZYcUDDfxne/A734Ht90Gc+fCJz4BxxwD48cn65cuhW9+Ex58ECrz+es2s94tn1emCRO2XfajH8GAAcTZZzPr5qeZNHZYsnz//eGEEzre129+AxdfnCSLyZPhJz+B3/9+SyL4whfgox+Fk07q7rMwM+sW+UwEbW3aBPfeC3/7tyzVLqzYUM+RhwwtbtuGBtil4M6iXXeFurpk+sEH4bHHYOHCbg/ZzKy75LOPoK377oO33oLzzmPOq2sBOGJMmgiuuipp0hk6NPnGP2/e1tsefzzcfju8/jo89BA880xSg6ivh0suSZqORozo2fMxM9sOTgQAd9wBe+wBp5/O3KXrqerfj3H7DIfPfAZuvhkefRS+970kCZx0EixYsGXba65JagX77AOTJsHll8OJJ8K118KoUUlHsplZL+amoeXLkzb9yy6DykrmLVvHofsMpXLMaLjppi3l3vOe5EJ/6KHwrW/BnXcmy0ePhmefhcWLYdiw5Nv/4sXw3e/CH/8Ib7+ddELfd1/SbPSlLyU1BTOzXsKJ4M47oaUFzjuP5pZg/vINfKxmbPtlx46Fd78bZs3aermU3Dra6pJL4FOfSm4Z/cpXYPZseO45WLYsSSgTJsCpp2Z3TmZm26HopiFJ2/3mdkmTJC2UtEjSle2sr5b0qKSnJc2VdMb2HmOn3X57csE+8kgWr6plU0Mzh43uoqNY6njdr36V9BNMm5bMP/ggnHde0kx01FHwgQ8ky8zMeokuE4GkkyQ9D7yQzh8p6YdFbFcB3ACcDkwAzpHU9r7NfwLuiYijgSlAl/vtVrNnw/PPJxdqYN6y9UBBR3Fbr72WNPccd1z76zdtSpqYrr9+62cNNm7cMl1bCxHdEb2ZWbcopmnoeuCDwAyAiHhW0nuL2O44YFFELAaQdDdwJvB8QZkAdkunhwLLi4y7e9xxR3JH0LnnAjB36Xp26V/BAaMGJ52+LS1Jx++oUcktoN/+NvTrlzT3tOcb34CDD4aPfWzLsve/H/7jP+CQQ5L+iIcfTvZtZtZLFNVHEBFLtHVzSHMRm40GlhTMLwWOb1Pma8BvJV0CDALe396OJE0FpgJUV1cXE3LXGhvhrruSDuA9kncOPLdsPRP22Y2Kfko6hW+8MXliuLY26QQ+5ZTkLqGDD952fy+8ADfcAHPmbL38q1+FlSvhwguT5w2+852kecjMrJcoJhEskXQSEJL6A5cBC7rYpljnALdFxPclnQj8l6TDIqKlsFBETAemA9TU1HRPu0r//rBq1ebZ1o7is49NO4ovvDD5FOuQQ7YdtgJg8GD48Y93Mlgzs+wU01n8WeDzJN/wlwFHpfNdWQYU3n4zJl1W6CLgHoCIeAKoAkYWse9u9/KbtbzdWERHsZlZmemyRhARbwLn7sC+ZwHjJe1HkgCmAB9vU+Y14FTgNknvIEkEqyiBhW/UAnDIXkO6KGlmVl6KuWvodknDCuZ3l3RrV9tFRBNwMfAQSVPSPRExX9I0Sa3DeV4OfFrSs8BdwPkRpbmlZuGKt+gnOHCPwaU4vJlZyRTTR3BERKxrnYmItZKOLmbnETETmNlm2dUF088D7you1Gy9+MZbjBsxiKr+FaUOxcysRxXTR9BP0u6tM5KGU4ZPJL+44i0O2tPNQmaWP8Vc0L8PPCHpXkDAR4BvZRpVD6trbOaV1Rv5myP3KXUoZmY9rpjO4jskzQHely76cNqkUzYWraylJdxRbGb5VGwTzwvA2tbykqoj4rXMouphf12V3DHkjmIzy6MuE0H61O81wAqSJ4pFMjTEEdmG1nOWrNkEwNjdt3tcPTOzPq+YGsFlwMERsTrrYErltTWbGDl4ILsM8B1DZpY/xdw1tARYn3UgpbRkzduMHb5L1wXNzMpQMTWCxcBjkn4N1LcujIgfZBZVZxYuhIkTu3WXX35tHYOrKuEe9xGYWf4UkwheSz8D0k9ZiYD65hZGVvr1zWaWT8XcPvr1ngikaAcfDI891m27W7pmE1Oue5Rrzzqcs4/tpiGuzcx6m07erFjMXUOjgC8Dh5IMCgdARJzSHbGVmu8YMrO8K6Y95CckzxHsB3wdeIVkZNGy8FprIhjuRGBm+VRMIhgREf8JNEbE4xFxIVAWtQGA5evepp9g76FVXRc2MytDxXQWN6Y/X5f0IZL3Cg/PLqSetaq2nuGDBlBZ4c5iM8unYhLBNyUNJXl3wL+TvGz+i5lG1YPerG1g5OCBpQ7DzKxkirlr6IF0cj1bBp4rG2/W1jNicNndFWtmVrQOE4GkL0fEdZL+nWRsoa1ExKWZRtZDVtc2UF09rNRhmJmVTGc1ggXpz9k9EUipvFlb76YhM8u1DhNBRNwvqQI4PCKu6MGYesymhiY2NTS7acjMcq3TW2UiopmdeKewpEmSFkpaJOnKdtZfL+mZ9POipHU7eqwdsbq2AcA1AjPLtWLuGnpG0gzgXmBj68KI+GVnG6W1iRuA04ClwCxJMwrfbhYRXywofwlw9PaFv3NW1SZj6I10jcDMcqyYRFAFrGbrh8gC6DQRAMcBiyJiMYCku4EzgY5ec3kOyQtweoxrBGZmxd0+esEO7ns0ybsMWi0Fjm+voKR9SYaweKSD9VOBqQDV1d03MNybaY1ghBOBmeVYMYPOVQEXse2gcxd2YxxTgJ+nfRLbiIjpwHSAmpqabW5l3VGrWxPBIDcNmVl+FTOuwn8BewEfBB4HxgBvFbHdMmBswfyYdFl7pgB3FbHPbvVmbQNDqiqp6u9XVJpZfhWTCA6MiK8CGyPiduBDdNDE08YsYLyk/SQNILnYz2hbSNIhwO7AE8WH3T38DIGZWXGJoHXQuXWSDgOGAnt0tVFENAEXAw+RPJx2T0TMlzRN0uSColOAuyOi25p8ipUkAjcLmVm+FXPX0HRJuwNfJflGPzid7lJEzARmtll2dZv5rxUVaQberG3gwFF+T7GZ5VtnYw09D/wUuCsi1pL0D+zfU4H1hNW19Zywf9mMqG1mtkM6axo6BxgE/FbSk5K+KGnvHoorc43NLazd1MiIQe4jMLN86zARRMSzEXFVRBwAXApUA3+R9KikT/dYhBlZuzF9mGyIE4GZ5VtRr+WKiD+nw0F8EhgG/EeWQfWE1uElRrmz2MxyrpgHyo4laSY6C3gZuJlk3KE+rXV4ieFuGjKznOuss/ifgbOBNcDdwLsiYmlPBZa1dW8nd8Xuvmv/EkdiZlZandUI6oBJEfFSTwXTkzakiWDoLk4EZpZvnb2YZlpPBtLT1qeJYDcnAjPLuaI6i8vRhrpGBlT28zhDZpZ7+U0EbzexW5VrA2ZmnXUWH9PZhhHxVPeH03M2vN3I0F2KGWHDzKy8dXYl/H76swqoAZ4FBBwBzAZOzDa0bG2oa3T/gJkZnT9Z/L6IeB/wOnBMRNRExDtJ3ivc0XsF+oz1bzf6jiEzM4rrIzg4Iua1zkTEc8A7sgupZ2x4u9F9BGZmFDcM9VxJtwB3pvPnAnOzC6lnuEZgZpYoJhFcAHwOuCyd/x/gxswi6gERwYa6JnZzZ7GZWdeJICLqJN0EzIyIhT0QU+Y2NjTT3BKuEZiZUUQfQfpayWeAB9P5oyRt8+7hvqR1eAn3EZiZFddZfA1wHLAOICKeAfYrZueSJklaKGmRpCs7KPMxSc9Lmi/pp8WFvXPWe5whM7PNimkkb4yI9ZIKl3X5onlJFcANwGnAUmCWpBkR8XxBmfHAVSQjm66VtMd2Rb+DNnicITOzzYqpEcyX9HGgQtJ4Sf8O/G8R2x0HLIqIxRHRQDKU9ZltynwauCF9JzIRsXI7Yt9hG+qaADcNmZlBcYngEuBQoB64C9gAfKGI7UYDSwrml6bLCh0EHCTpT5L+LGlSEfvdaW4aMjPbopi7hjYBX0k/WRx/PDARGAP8j6TDI2JdYSFJU4GpANXV1Tt90C1NQ7591MysmFdVHgRcAYwrLB8Rp3Sx6TJgbMH8GLYdmmIp8JeIaARelvQiSWKYVVgoIqYD0wFqamq67J/oyoa6JBEMcdOQmVlRncX3AjcBtwDN27HvWcB4SfuRJIApwMfblPkVyfuQfyxpJElT0eLtOMYO2dTQzC79K6jop64Lm5mVuWISQVNEbPeTxBHRJOli4CGgArg1IuZLmgbMjogZ6boPSHqeJMn8Q0Ss3t5jba/a+iYGDfQLaczMoLhEcL+kvwfuI+kwBiAi1nS1YUTMBGa2WXZ1wXQAX0o/PWZjfRODBrp/wMwMiksE56U//6FgWQD7d384PWNjfRODBjgRmJlBcXcNFfUUcV+ysb6Zwa4RmJkBnb+q8pSIeETSh9tbHxG/zC6sbG1saGL4oAGlDsPMrFfo7GvxycAjwN+2sy6APpsIauubGDt811KHYWbWK3SYCCLimvTnBT0XTs/YVN/MYPcRmJkBxXUWI+lDJMNMVLUui4hpWQWVNd81ZGa2RTHvI7gJOJtkzCEBHwX2zTiuzEQEGxv8HIGZWatiBp07KSI+CayNiK8DJ5I8Adwnvd3YTEvgGoGZWaqYRPB2+nOTpH2ARmDv7ELK1sb6ZJQMJwIzs0QxV8MHJA0Dvgs8RXLH0C1ZBpWljfXJuwgGDXDTkJkZFPdA2TfSyV9IegCoioj12YaVndrWROAagZkZ0PkDZe0+SJau67MPlG1qSJqG/GSxmVmis6thew+SteqzD5RtdI3AzGwrnT1QVnYPkkFB05D7CMzMgOKeIxgh6d8kPSVpjqR/lTSiJ4LLgmsEZmZbK+b20buBVcBZwEfS6Z9lGVSWNjb49lEzs0LFXA33LrhzCOCbks7OKqCs+fZRM7OtFVMj+K2kKZL6pZ+Pkbxisk/aWN/EwMp+VFYUc+pmZuWvmKvhp4Gfkrymsp6kqegzkt6StCHL4LJQW9/kW0fNzAp0mQgiYkhE9IuI/umnX7psSETs1tm2kiZJWihpkaQr21l/vqRVkp5JP5/amZMpxqaGZvcPmJkVKOauoYvazFdIuqaI7SqAG4DTgQnAOZImtFP0ZxFxVPrJfOiKjfVN7Or+ATOzzYppGjpV0kxJe0s6DPgzMKSI7Y4DFkXE4ohoIGlSOnMnYu0WdU0tDOzvRGBm1qqYsYY+nt4lNA/YCHw8Iv5UxL5HA0sK5pcCx7dT7ixJ7wVeBL4YEUvaFpA0FZgKUF1dXcShO1bf2ExVpTuKzcxaFdM0NB64DPgF8CrwCUnd9cLf+4FxEXEE8Dvg9vYKRcT0iKiJiJpRo0bt1AHrmlqoco3AzGyzYr4a3w98NSI+Q/JC+5eAWUVstwwYWzA/Jl22WUSsjoj6dPYW4J1F7Hen1Dc2U9XfNQIzs1bFXBGPi4iHASLxfeDvithuFjBe0n6SBgBTgBmFBSQVvuBmMrCguLB3XF1js2sEZmYFOkwEkr4MEBEbJH20zerzu9pxRDQBF5M8fLYAuCci5kuaJmlyWuxSSfMlPQtcWsx+d1ZdYwsD3UdgZrZZZ1fEKQXTV7VZN6mYnUfEzIg4KCIOiIhvpcuujogZ6fRVEXFoRBwZEe+LiBe2K/odUNfkGoGZWaHOEoE6mG5vvs9w05CZ2dY6SwTRwXR7831CRFDf1OLbR83MCnT2HMGR6VhCAnYpGFdIQFXmkWWgobmFCPxAmZlZgc7eUFZ2V8u6xhYANw2ZmRXIVRtJfWPyUho/R2BmtkWuroitNYKBla4RmJm1ylciaHKNwMysrVxdEetb+whcIzAz2yxXiWBLjcCJwMysVb4SgTuLzcy2kasrom8fNTPbVs4SgWsEZmZt5eqK2JoIfPuomdkW+UoETelzBK4RmJltlqsr4pYni10jMDNrla9E0OTnCMzM2spVIqhrbKafoH9Fn32dgplZt8tdIqjqX4HkRGBm1ipnicDvKzYzayvTq6KkSZIWSlok6cpOyp0lKSTVZBmPX1NpZratzBKBpArgBuB0YAJwjqQJ7ZQbAlwG/CWrWFrVN7U4EZiZtZFljeA4YFFELI6IBuBu4Mx2yn0DuBaoyzAWIKkRuGnIzGxrWV4VRwNLCuaXpss2k3QMMDYift3ZjiRNlTRb0uxVq1btcEB1rhGYmW2jZF+PJfUDfgBc3lXZiJgeETURUTNq1KgdPmbSR+AagZlZoSyvisuAsQXzY9JlrYYAhwGPSXoFOAGYkWWHcb07i83MtpFlIpgFjJe0n6QBwBRgRuvKiFgfESMjYlxEjAP+DEyOiNlZBeTbR83MtpXZVTEimoCLgYeABcA9ETFf0jRJk7M6bmfqm1wjMDNrqzLLnUfETGBmm2VXd1B2YpaxADQ2BwMqXCMwMyuUq6tiQ3ML/d00ZGa2lVxdFRubW1wjMDNrI1dXxcamFir7ecA5M7NC+UoEzeGmITOzNnJzVYyIpI/ATUNmZlvJzVWxuSUAGOCX0piZbSU3iaCxOUkEla4RmJltJTdXxYbm5H3FbhoyM9tabq6KjWkicNOQmdnWcpcIXCMwM9tabq6KTWkfgROBmdnWcnNVbO0jqHTTkJnZVnKTCLb0EeTmlM3MipKbq2Jjk5uGzMzak5ur4ubbRz3EhJnZVnJzVdxy15D7CMzMCuUmEfiuITOz9uXmqujnCMzM2pebq2KDm4bMzNqVaSKQNEnSQkmLJF3ZzvrPSpon6RlJf5Q0IatYfPuomVn7MrsqSqoAbgBOByYA57Rzof9pRBweEUcB1wE/yCqexs0PlDkRmJkVyvKqeBywKCIWR0QDcDdwZmGBiNhQMDsIiKyCadzcWeymITOzQpUZ7ns0sKRgfilwfNtCkj4PfAkYAJzS3o4kTQWmAlRXV+9QMG4aMjNrX8mvihFxQ0QcAPwj8E8dlJkeETURUTNq1KgdOk5jk+8aMjNrT5ZXxWXA2IL5MemyjtwN/J+sgtncNOQni83MtpLlVXEWMF7SfpIGAFOAGYUFJI0vmP0Q8FJWwYwbOYgzDt/LTUNmZm1k1kcQEU2SLgYeAiqAWyNivqRpwOyImAFcLOn9QCOwFjgvq3hOm7Anp03YM6vdm5n1WVl2FhMRM4GZbZZdXTB9WZbHNzOzrrmdxMws55wIzMxyzonAzCznnAjMzHLOicDMLOecCMzMcs6JwMws5xSR2YCfmZC0Cnh1BzcfCbzZjeH0dnk63zydK/h8y1lW57pvRLQ7WFufSwQ7Q9LsiKgpdRw9JU/nm6dzBZ9vOSvFubppyMws55wIzMxyLm+JYHqpA+hheTrfPJ0r+HzLWY+fa676CMzMbFt5qxGYmVkbTgRmZjmXm0QgaZKkhZIWSbqy1PF0B0m3Slop6bmCZcMl/U7SS+nP3dPlkvRv6fnPlXRM6SLffpLGSnpU0vOS5ku6LF1educrqUrSk5KeTc/16+ny/ST9JT2nn6Vv/kPSwHR+Ubp+XElPYAdJqpD0tKQH0vmyPF9Jr0iaJ+kZSbPTZSX9O85FIpBUAdwAnA5MAM6RNKG0UXWL24BJbZZdCTwcEeOBh9N5SM59fPqZCtzYQzF2lybg8oiYAJwAfD79NyzH860HTomII4GjgEmSTgCuBa6PiANJ3uh3UVr+ImBtuvz6tFxfdBmwoGC+nM/3fRFxVMHzAqX9O46Isv8AJwIPFcxfBVxV6ri66dzGAc8VzC8E9k6n9wYWptM3A+e0V64vfoD/Bk4r9/MFdgWeAo4nedq0Ml2++W+a5HWwJ6bTlWk5lTr27TzPMSQXwFOABwCV6/kCrwAj2ywr6d9xLmoEwGhgScH80nRZOdozIl5Pp98AWl/UXDa/g7Qp4GjgL5Tp+abNJM8AK4HfAX8F1kVEU1qk8Hw2n2u6fj0wokcD3nn/AnwZaEnnR1C+5xvAbyXNkTQ1XVbSv+NM31lspRURIams7g+WNBj4BfCFiNggafO6cjrfiGgGjpI0DLgPOKS0EWVH0t8AKyNijqSJJQ6nJ7w7IpZJ2gP4naQXCleW4u84LzWCZcDYgvkx6bJytELS3gDpz5Xp8j7/O5DUnyQJ/CQifpkuLtvzBYiIdcCjJE0jwyS1fnkrPJ/N55quHwqs7tlId8q7gMmSXgHuJmke+lfK9HwjYln6cyVJkj+OEv8d5yURzALGp3chDACmADNKHFNWZgDnpdPnkbSlty7/ZHoXwgnA+oKqaK+n5Kv/fwILIuIHBavK7nwljUprAkjahaQvZAFJQvhIWqztubb+Dj4CPBJpg3JfEBFXRcSYiBhH8n/zkYg4lzI8X0mDJA1pnQY+ADxHqf+OS91x0oMdNGcAL5K0tX6l1PF00zndBbwONJK0HV5E0lb6MPAS8HtgeFpWJHdO/RWYB9SUOv7tPNd3k7StzgWeST9nlOP5AkcAT6fn+hxwdbp8f+BJYBFwLzAwXV6Vzi9K1+9f6nPYiXOfCDxQruebntOz6Wd+67Wo1H/HHmLCzCzn8tI0ZGZmHXAiMDPLOScCM7OccyIwM8s5JwIzs5xzIrBeR1JI+n7B/BWSvpbBce5KR3T8YjvrPinpuXSUyKclXdHdx+9pkv5fqWOw3smJwHqjeuDDkkZmdQBJewHHRsQREXF9m3WnA18APhARh5OMdro+q1h6kBOBtcuJwHqjJpL3trb3TX2cpEfSb/IPS6rubEfp2P4/Lvhm/7501W+B0emY8O9ps9lVwBURsRwgIuoj4kfp/o6S9Of0+PcVjBv/mKTrJc2WtEDSsZJ+mY4v/82C2F+Q9JO0zM8l7ZquOzWNb56S90wMTJe/Iunrkp5K1x2SLh+Ulnsy3e7MdPn56XEfTI99Xbr8O8Au6fn+JN3+10reefCcpLO3+1/Jykepn7Tzx5+2H6AW2I1kuN6hwBXA19J19wPnpdMXAr/qYl+XA7em04cAr5E8mTqOguG722yzBhjawbq5wMnp9DTgX9Lpx4Br0+nLgOUkwwkPJHnqe0R6zADelZa7NT23KpIRJg9Kl99BMqge6e/gknT674Fb0ul/Bv5vOj2M5Kn5QcD5wOL091YFvAqMbf29FpzHWcCPCubbPV9/8vFxjcB6pYjYQHJBvLTNqhOBn6bT/0Uy9ERn3g3cme7zBZIL40E7EpOkocCwiHg8XXQ78N6CIq3jV80D5kfE6xFRT3Jhbh04bElE/CmdvjON72Dg5Yh4sYP9tg6wN4ckmUAyRs2VSoaqfozkot9aO3o4ItZHRB3wPLBvO6czDzhN0rWS3hMR5dD0ZTvIicB6s38hGT9pUA8fdz7wzh3Yrj792VIw3TrfOopm2zFdihnjpXVfzQX7EXBWJG+5OioiqiNiQZvybbfZctAk6RxDkhC+KenqIuKwMuVEYL1WRKwB7mHLKwoB/pdkhEqAc4E/dLGbP6TlkHQQybfmhV1s823gu2mHMpIGSPpU+q15bUGfwieAxzvaSQeqJZ2YTn8c+GMazzhJB27Hfh8CLklHZUXS0UUcuzEdyhtJ+wCbIuJO4LskScFyyi+msd7u+8DFBfOXAD+W9A/AKuACAEmfBYiIm9ps/0PgRknzSDqhz4+IehW80KatiJgpaU/g9+mFNkja8yEZIvimtJN3cevxt8NCkvct30rSbHNjRNRJugC4V8n4+rOAtufR1jdIakxzJfUDXgb+pottpqflnyJpdvuupBaS0Ws/t53nYWXEo4+a9RAlr9h8ICIOK3UsZoXcNGRmlnOuEZiZ5ZxrBGZmOedEYGaWc04EZmY550RgZpZzTgRmZjn3/wEecdCWN1EriAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot No. of Components vs. Explained Variance and mark at 75% explained variance\n",
    "pca = PCA().fit(X_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('No. of Components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.axhline(y=0.75, color='r', linestyle='-')\n",
    "plt.text(0.5, 0.8, '75%', color = 'red', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Components: 13\n"
     ]
    }
   ],
   "source": [
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components = np.argmax(cumulative_explained_variance >= 0.75) + 1\n",
    "print(\"No. of Components:\", n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on the data and extract the features that explain 75% of the variance\n",
    "pca = PCA(n_components=0.75)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Logistic Regression \n",
    "# Initialize Logistic Regression\n",
    "lr_pca = LogisticRegression(max_iter=1000, C=best_parameters['C'], penalty=best_parameters['penalty'], solver=best_parameters['solver'])\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_test_pca = lr_pca.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with PCA: Test Data\n",
      "Accuracy Score: 0.8813333333333333\n",
      "Confusion Matrix:\n",
      " [[3165  543]\n",
      " [ 347 3445]]\n",
      "AUC Score: 0.8810257158657981\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88      3708\n",
      "           1       0.86      0.91      0.89      3792\n",
      "\n",
      "    accuracy                           0.88      7500\n",
      "   macro avg       0.88      0.88      0.88      7500\n",
      "weighted avg       0.88      0.88      0.88      7500\n",
      "\n",
      "Weighted F1-score: 0.8812173952673593\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score\n",
    "print(\"Logistic Regression with PCA: Test Data\")\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_test_pca))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test_pca))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_pred_test_pca))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_test_pca))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_test, y_pred_test_pca, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with PCA: Training Data\n",
      "Accuracy Score: 0.8755111111111111\n",
      "Confusion Matrix:\n",
      " [[ 9693  1599]\n",
      " [ 1202 10006]]\n",
      "AUC Score: 0.8755752494991812\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87     11292\n",
      "           1       0.86      0.89      0.88     11208\n",
      "\n",
      "    accuracy                           0.88     22500\n",
      "   macro avg       0.88      0.88      0.88     22500\n",
      "weighted avg       0.88      0.88      0.88     22500\n",
      "\n",
      "Weighted F1-score: 0.8754805489225298\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "# Predict on the training data\n",
    "y_pred_train_pca = lr_pca.predict(X_train_pca)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Logistic Regression with PCA: Training Data\")\n",
    "print(\"Accuracy Score:\", accuracy_score(y_train, y_pred_train_pca))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_pred_train_pca))\n",
    "\n",
    "# Print AUC score\n",
    "print(\"AUC Score:\", roc_auc_score(y_train, y_pred_train_pca))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_pred_train_pca))\n",
    "\n",
    "# Print weighted F1-score\n",
    "print(\"Weighted F1-score:\", f1_score(y_train, y_pred_train_pca, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
